{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "# from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import re\n",
    "import time\n",
    "import os\n",
    "import pickle\n",
    "import time\n",
    "\n",
    "from selenium.webdriver.common.desired_capabilities import DesiredCapabilities\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.common.exceptions import NoSuchElementException\n",
    "from collections import defaultdict\n",
    "\n",
    "import pipeline as p\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "caps = DesiredCapabilities().CHROME\n",
    "caps[\"pageLoadStrategy\"] = \"none\"\n",
    "\n",
    "pd.set_eng_float_format(accuracy=1, use_eng_prefix=True)\n",
    "\n",
    "chromedriver = \"/Users/kendra/Applications/chromedriver\" # path to the chromedriver executable\n",
    "os.environ[\"webdriver.chrome.driver\"] = chromedriver\n",
    "\n",
    "url_base = 'https://www.pro-football-reference.com'\n",
    "\n",
    "team_dict = p.open_pkl('TeamDicts/team_dictionary.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a dictionary to track which teams & seasons we've scraped data for"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# season_dict:\n",
    "    # key = [year] \n",
    "    # vals = list of teams whose team-season page has been sucessfully scraped\n",
    "\n",
    "# season_dict = p.open_pkl('Data/season_dict.pkl')    # use this if need to re-start scraping\n",
    "season_dict = defaultdict(list)  # [year] = list of teams whose team-season page has been sucessfully scraped"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Iterate over team-season pages, and boxscores within a given season:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018\n",
      "Loading page for nwe 2018\n",
      "Page loaded & data found!\n"
     ]
    }
   ],
   "source": [
    "driver = webdriver.Chrome(chromedriver, desired_capabilities=caps)\n",
    "# driver = webdriver.Chrome(chromedriver)\n",
    "\n",
    "for year in range(2018, 2019):\n",
    "    print(year)\n",
    "    bxsc_html = defaultdict(list)    # [href] = html -- also tracks whether a bxsc href has been visited\n",
    "    bxsc_refs = {}                   # [team-year] = list of hrefs for boxscores\n",
    "    season_html = {}                 # [team-year] = html of team season page\n",
    "    \n",
    "    for tm_list in team_dict.values():\n",
    "        team, url = tm_list[1], tm_list[2]\n",
    "        tm_yr = team +'-' + str(year)\n",
    "        if team not in season_dict[year]:\n",
    "\n",
    "            # get html of season data table\n",
    "            html = p.get_season_data(url, year, driver)\n",
    "\n",
    "            # if successfully returned data:\n",
    "            if html:\n",
    "                # add html to season_html dictionary\n",
    "                season_html[tm_yr] = html\n",
    "\n",
    "                # generate list of individaul game boxscore URLs, add them to bxsc_refs dictionary\n",
    "                href_list = p.get_href_list(html)\n",
    "                bxsc_refs[tm_yr] = href_list\n",
    "\n",
    "                # get & add bxsc html's to bxsc_html dict\n",
    "                for a in href_list:\n",
    "                    href = a.attrs['href']\n",
    "                    if href not in bxsc_html.keys():\n",
    "                        bxsc_html[href] = p.get_bxsc_data(href, driver)\n",
    "\n",
    "                # add team & year to season dictionary\n",
    "                season_dict[year].append(team)\n",
    "\n",
    "#     p.pkl_this('bxsc_refs_' + str(year) + '.pkl',bxsc_refs)\n",
    "    p.save_dict_txt('Data/bxsc_refs_' + str(year) + '.txt', bxsc_refs)\n",
    "    p.pkl_this('Data/bxsc_html_' + str(year) + '.pkl', bxsc_html)   # changed this to include year after I ran\n",
    "    p.pkl_this('Data/season_html_' + str(year) + '.pkl', season_html)\n",
    "    p.pkl_this('Data/season_dict.pkl', season_dict)\n",
    "    \n",
    "p.close_dr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Elo Data from FiveThirthyEight"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "File downloaded from: https://projects.fivethirtyeight.com/nfl-api/nfl_elo.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime as dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "elo_df = pd.read_csv('Data/nfl_games.csv')\n",
    "elo_df['date'] = pd.to_datetime(elo_df['date'], format='%Y-%m-%d')\n",
    "\n",
    "# Can drop anything before 2007\n",
    "elo_df = elo_df[elo_df['date'] >= dt.datetime(2007,8,1)].reset_index(drop=True)\n",
    "\n",
    "p.pkl_this('Data/elo_df.pkl', elo_df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
